{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIcQcinewhfKFcyq1lW9OU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivaShirsath/nlp/blob/master/3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wHcHeuIqPQ7i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# load dataset\n",
        "!wget https://github.com/PICT-NLP/BE-NLP-Elective/raw/main/3-Preprocessing/News_dataset.pickle\n",
        "with open('News_dataset.pickle', 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "\n",
        "# convert dataset into pandas dataframe\n",
        "df = pd.DataFrame(dataset, columns=['Content', 'category'])\n",
        "\n",
        "# convert text column to string type\n",
        "df['Content'] = df['Content'].astype(str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccxE4nQDs7F1",
        "outputId": "9cda5d05-718b-491f-d196-91b343e6d527"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-08 17:15:54--  https://github.com/PICT-NLP/BE-NLP-Elective/raw/main/3-Preprocessing/News_dataset.pickle\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/PICT-NLP/BE-NLP-Elective/main/3-Preprocessing/News_dataset.pickle [following]\n",
            "--2023-03-08 17:15:55--  https://raw.githubusercontent.com/PICT-NLP/BE-NLP-Elective/main/3-Preprocessing/News_dataset.pickle\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4980629 (4.7M) [application/octet-stream]\n",
            "Saving to: ‘News_dataset.pickle.2’\n",
            "\n",
            "News_dataset.pickle 100%[===================>]   4.75M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-03-08 17:15:55 (81.3 MB/s) - ‘News_dataset.pickle.2’ saved [4980629/4980629]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text cleaning\n",
        "df['Content'] = df['Content'].str.lower()\n",
        "df['Content'] = df['Content'].str.replace('[^\\w\\s]','')\n",
        "df['Content'] = df['Content'].str.replace('\\d+','')\n",
        "print('Text Cleaning', df['Content'], sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V49CC6qtDv7",
        "outputId": "225af626-a2aa-46fa-f8cc-f92537119ee3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-dd5f094d1282>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['Content'] = df['Content'].str.replace('[^\\w\\s]','')\n",
            "<ipython-input-3-dd5f094d1282>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['Content'] = df['Content'].str.replace('\\d+','')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Cleaning\n",
            "0       ad sales boost time warner profit\\r\\n\\r\\nquart...\n",
            "1       dollar gains on greenspan speech\\r\\n\\r\\nthe do...\n",
            "2       yukos unit buyer faces loan claim\\r\\n\\r\\nthe o...\n",
            "3       high fuel prices hit bas profits\\r\\n\\r\\nbritis...\n",
            "4       pernod takeover talk lifts domecq\\r\\n\\r\\nshare...\n",
            "                              ...                        \n",
            "2220    bt program to beat dialler scams\\r\\n\\r\\nbt is ...\n",
            "2221    spam emails tempt net shoppers\\r\\n\\r\\ncomputer...\n",
            "2222    be careful how you code\\r\\n\\r\\na new european ...\n",
            "2223    us cyber security chief resigns\\r\\n\\r\\nthe man...\n",
            "2224    losing yourself in online gaming\\r\\n\\r\\nonline...\n",
            "Name: Content, Length: 2225, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['Content'] = df['Content'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
        "print('Lemmatization', df['Content'], sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IPrG1smtIkT",
        "outputId": "42824d0b-70dd-45e4-8351-d3cc809216ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatization\n",
            "0       ad sale boost time warner profit quarterly pro...\n",
            "1       dollar gain on greenspan speech the dollar ha ...\n",
            "2       yukos unit buyer face loan claim the owner of ...\n",
            "3       high fuel price hit ba profit british airway h...\n",
            "4       pernod takeover talk lift domecq share in uk d...\n",
            "                              ...                        \n",
            "2220    bt program to beat dialler scam bt is introduc...\n",
            "2221    spam email tempt net shopper computer user acr...\n",
            "2222    be careful how you code a new european directi...\n",
            "2223    u cyber security chief resigns the man making ...\n",
            "2224    losing yourself in online gaming online role p...\n",
            "Name: Content, Length: 2225, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stop word removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['Content'] = df['Content'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "print('Stop World Removal :', df['Content'], sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7nof3UutNJU",
        "outputId": "26c198b5-6ceb-414e-d320-d4b5d615aa7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop World Removal :\n",
            "0       ad sale boost time warner profit quarterly pro...\n",
            "1       dollar gain greenspan speech dollar ha hit hig...\n",
            "2       yukos unit buyer face loan claim owner embattl...\n",
            "3       high fuel price hit ba profit british airway h...\n",
            "4       pernod takeover talk lift domecq share uk drin...\n",
            "                              ...                        \n",
            "2220    bt program beat dialler scam bt introducing tw...\n",
            "2221    spam email tempt net shopper computer user acr...\n",
            "2222    careful code new european directive could put ...\n",
            "2223    u cyber security chief resigns man making sure...\n",
            "2224    losing online gaming online role playing game ...\n",
            "Name: Content, Length: 2225, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoding\n",
        "encoder = LabelEncoder()\n",
        "df['category'] = encoder.fit_transform(df['category'])\n",
        "print('Label Encoding :', df['category'], sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LTMmdDLtRo_",
        "outputId": "41551784-5995-42af-cd9e-7809a9c9f85a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Encoding :\n",
            "0       0\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "2220    0\n",
            "2221    0\n",
            "2222    0\n",
            "2223    0\n",
            "2224    0\n",
            "Name: category, Length: 2225, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF vectorization\n",
        "tfidf = TfidfVectorizer()\n",
        "X = tfidf.fit_transform(df['Content'])\n",
        "print('TF-IDF vectorization :', X, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeyu8LW9tVtC",
        "outputId": "f887c9d2-8dda-4dd4-f460-a97efc235f19"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF vectorization :\n",
            "  (0, 26414)\t0.033779095839948876\n",
            "  (0, 14531)\t0.035679398862105735\n",
            "  (0, 2834)\t0.03497465413990564\n",
            "  (0, 20616)\t0.0333300422119466\n",
            "  (0, 8209)\t0.056540162120040066\n",
            "  (0, 23528)\t0.12250717057240096\n",
            "  (0, 19589)\t0.043941859745335654\n",
            "  (0, 2381)\t0.07119523633370005\n",
            "  (0, 19546)\t0.04807566061589116\n",
            "  (0, 16330)\t0.02877989870995396\n",
            "  (0, 10065)\t0.03768197016859518\n",
            "  (0, 26960)\t0.020738517863256638\n",
            "  (0, 311)\t0.06143631265777171\n",
            "  (0, 12499)\t0.05074147624778164\n",
            "  (0, 19217)\t0.03609651563636007\n",
            "  (0, 20681)\t0.04315174321728093\n",
            "  (0, 14016)\t0.03205054694793624\n",
            "  (0, 1452)\t0.04577043430820242\n",
            "  (0, 22174)\t0.04366836388755726\n",
            "  (0, 16553)\t0.03162746912538339\n",
            "  (0, 876)\t0.03425206447384327\n",
            "  (0, 8166)\t0.04054915173228801\n",
            "  (0, 25817)\t0.043941859745335654\n",
            "  (0, 20876)\t0.037888559831885604\n",
            "  (0, 6043)\t0.055375890220680846\n",
            "  :\t:\n",
            "  (2224, 17224)\t0.02221419561911395\n",
            "  (2224, 18008)\t0.014226840610686036\n",
            "  (2224, 163)\t0.010337060435573104\n",
            "  (2224, 1359)\t0.016345009186111755\n",
            "  (2224, 10586)\t0.018084339119436056\n",
            "  (2224, 26786)\t0.07197608717862375\n",
            "  (2224, 2421)\t0.008558109033986796\n",
            "  (2224, 22587)\t0.010887708783679662\n",
            "  (2224, 25566)\t0.01925866134864499\n",
            "  (2224, 17390)\t0.2195033707232518\n",
            "  (2224, 1790)\t0.00647489969414862\n",
            "  (2224, 12817)\t0.014328624612159184\n",
            "  (2224, 11645)\t0.0147803599980536\n",
            "  (2224, 10690)\t0.019841893995559863\n",
            "  (2224, 3408)\t0.008270796619870723\n",
            "  (2224, 9641)\t0.010011356294854912\n",
            "  (2224, 13938)\t0.03529071458368669\n",
            "  (2224, 9814)\t0.02378835652366874\n",
            "  (2224, 21468)\t0.006438470452276629\n",
            "  (2224, 12561)\t0.009960615622316305\n",
            "  (2224, 17339)\t0.0340316812269385\n",
            "  (2224, 16029)\t0.019367877852091268\n",
            "  (2224, 24936)\t0.006581456413905688\n",
            "  (2224, 25054)\t0.117156804073817\n",
            "  (2224, 21487)\t0.008086082276204082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save outputs\n",
        "np.save('X.npy', X.toarray())\n",
        "np.save('y.npy', df['category'].to_numpy())\n",
        "print(\"Saved : \", np.load('X.npy'), sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXmCI1OztZ-S",
        "outputId": "6629efa0-d794-409a-a488-49c4b08c7705"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved : \n",
            "[[0.         0.         0.         ... 0.02701782 0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.03502724 0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.02526516 0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
          ]
        }
      ]
    }
  ]
}