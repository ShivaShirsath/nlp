{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbC3C5cZ8j4aJxACgxMI2z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivaShirsath/nlp/blob/master/2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "im27wmEsTb7-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "# Load the dataset\n",
        "df = pd.read_csv('data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1273gTNP8bZ2",
        "outputId": "2d7bec32-609f-48f3-968f-3e624cc9d686"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the text to use for feature extraction\n",
        "text_columns = ['Make', 'Model', 'Engine Fuel Type', 'Transmission Type', 'Driven_Wheels', 'Market Category', 'Vehicle Size', 'Vehicle Style']\n",
        "text = df[text_columns].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
        "\n",
        "# Clean the text by removing special characters, digits, and stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "text = text.apply(lambda x: re.sub('[^a-zA-Z\\s]', '', x))\n",
        "text = text.apply(lambda x: re.sub(r'\\d+', '', x))\n",
        "text = text.apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
        "print(\"Text : \", text, sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFD-anZB8h83",
        "outputId": "164a7989-23f3-40b3-81ba-efe1ac837998"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text : \n",
            "0        BMW Series premium unleaded required MANUAL re...\n",
            "1        BMW Series premium unleaded required MANUAL re...\n",
            "2        BMW Series premium unleaded required MANUAL re...\n",
            "3        BMW Series premium unleaded required MANUAL re...\n",
            "4        BMW Series premium unleaded required MANUAL re...\n",
            "                               ...                        \n",
            "11909    Acura ZDX premium unleaded required AUTOMATIC ...\n",
            "11910    Acura ZDX premium unleaded required AUTOMATIC ...\n",
            "11911    Acura ZDX premium unleaded required AUTOMATIC ...\n",
            "11912    Acura ZDX premium unleaded recommended AUTOMAT...\n",
            "11913    Lincoln Zephyr regular unleaded AUTOMATIC fron...\n",
            "Length: 11914, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create bag-of-words features using count occurrence and normalized count occurrence\n",
        "count_vec = CountVectorizer()\n",
        "X_count = count_vec.fit_transform(text)\n",
        "X_count_norm = X_count / np.sum(X_count, axis=1)\n",
        "print(\"\\nCount Occurrence :\", X_count, sep=\"\\n\")\n",
        "print(\"\\nNormalized Count Occurrence :\", X_count_norm, sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTO8xiv98n2l",
        "outputId": "e480db90-a3b0-48b7-db2a-3cd439b4b0d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Count Occurrence :\n",
            "  (0, 51)\t1\n",
            "  (0, 559)\t1\n",
            "  (0, 484)\t1\n",
            "  (0, 673)\t1\n",
            "  (0, 521)\t1\n",
            "  (0, 402)\t1\n",
            "  (0, 512)\t1\n",
            "  (0, 704)\t1\n",
            "  (0, 185)\t1\n",
            "  (0, 245)\t1\n",
            "  (0, 667)\t1\n",
            "  (0, 115)\t1\n",
            "  (0, 127)\t1\n",
            "  (1, 51)\t1\n",
            "  (1, 559)\t1\n",
            "  (1, 484)\t1\n",
            "  (1, 673)\t1\n",
            "  (1, 521)\t1\n",
            "  (1, 402)\t1\n",
            "  (1, 512)\t1\n",
            "  (1, 704)\t1\n",
            "  (1, 185)\t1\n",
            "  (1, 115)\t1\n",
            "  (1, 395)\t1\n",
            "  (1, 120)\t1\n",
            "  :\t:\n",
            "  (11911, 724)\t1\n",
            "  (11911, 141)\t1\n",
            "  (11912, 484)\t1\n",
            "  (11912, 673)\t1\n",
            "  (11912, 704)\t1\n",
            "  (11912, 185)\t1\n",
            "  (11912, 420)\t1\n",
            "  (11912, 29)\t1\n",
            "  (11912, 514)\t1\n",
            "  (11912, 314)\t1\n",
            "  (11912, 184)\t1\n",
            "  (11912, 6)\t1\n",
            "  (11912, 724)\t1\n",
            "  (11912, 141)\t1\n",
            "  (11913, 673)\t1\n",
            "  (11913, 704)\t1\n",
            "  (11913, 185)\t1\n",
            "  (11913, 391)\t1\n",
            "  (11913, 518)\t1\n",
            "  (11913, 271)\t1\n",
            "  (11913, 420)\t1\n",
            "  (11913, 552)\t1\n",
            "  (11913, 29)\t1\n",
            "  (11913, 381)\t1\n",
            "  (11913, 725)\t1\n",
            "\n",
            "Normalized Count Occurrence :\n",
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.08333333 0.         0.        ]\n",
            " [0.         0.         0.         ... 0.08333333 0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.09090909 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create bag-of-words features using TF-IDF\n",
        "tfidf_vec = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vec.fit_transform(text)\n",
        "print(\"\\nTF-IDF :\", X_tfidf, sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qlp6A4XX8tFo",
        "outputId": "5f520c2f-43b5-4e22-cee0-f130ced488a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF :\n",
            "  (0, 127)\t0.29155512347301105\n",
            "  (0, 115)\t0.17180852763247648\n",
            "  (0, 667)\t0.4173474512280893\n",
            "  (0, 245)\t0.38395763600012056\n",
            "  (0, 185)\t0.08964700037823825\n",
            "  (0, 704)\t0.08964700037823825\n",
            "  (0, 512)\t0.20280769809182894\n",
            "  (0, 402)\t0.2152200361399859\n",
            "  (0, 521)\t0.24918848483841655\n",
            "  (0, 673)\t0.09857959161354882\n",
            "  (0, 484)\t0.1966191494248329\n",
            "  (0, 559)\t0.4265343565320581\n",
            "  (0, 51)\t0.40981434665401595\n",
            "  (1, 120)\t0.36307337671360584\n",
            "  (1, 395)\t0.3828183207136555\n",
            "  (1, 115)\t0.18946546514426285\n",
            "  (1, 185)\t0.0988601139856354\n",
            "  (1, 704)\t0.0988601139856354\n",
            "  (1, 512)\t0.22365045194964012\n",
            "  (1, 402)\t0.2373384186310876\n",
            "  (1, 521)\t0.27479783942680275\n",
            "  (1, 673)\t0.10871071672732242\n",
            "  (1, 484)\t0.21682589982805686\n",
            "  (1, 559)\t0.4703697271256941\n",
            "  (1, 51)\t0.4519313847895299\n",
            "  :\t:\n",
            "  (11911, 673)\t0.0780478668206422\n",
            "  (11911, 484)\t0.1556681757097905\n",
            "  (11912, 141)\t0.5871480489107743\n",
            "  (11912, 724)\t0.5871480489107743\n",
            "  (11912, 6)\t0.3429930416948985\n",
            "  (11912, 184)\t0.15082338608041232\n",
            "  (11912, 314)\t0.23242468741069475\n",
            "  (11912, 514)\t0.21605708601978396\n",
            "  (11912, 29)\t0.09652725492246407\n",
            "  (11912, 420)\t0.1415272252259404\n",
            "  (11912, 185)\t0.07068867596124924\n",
            "  (11912, 704)\t0.07068867596124924\n",
            "  (11912, 673)\t0.0777322250444648\n",
            "  (11912, 484)\t0.15503862129047175\n",
            "  (11913, 725)\t0.7771177780195518\n",
            "  (11913, 381)\t0.4233084214332946\n",
            "  (11913, 29)\t0.10948518229469044\n",
            "  (11913, 552)\t0.18945937467880986\n",
            "  (11913, 420)\t0.16052599927316205\n",
            "  (11913, 271)\t0.15327511232394786\n",
            "  (11913, 518)\t0.11942616939791792\n",
            "  (11913, 391)\t0.291309377816706\n",
            "  (11913, 185)\t0.08017800340436854\n",
            "  (11913, 704)\t0.08017800340436854\n",
            "  (11913, 673)\t0.08816708644621922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model to create embeddings\n",
        "sentences = [nltk.word_tokenize(sent) for sent in text]\n",
        "w2v_model = Word2Vec(sentences, size=100, min_count=1)\n",
        "print(\"\\nWord2Vec :\", w2v_model, sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHR2ytGc8wiU",
        "outputId": "c7a05eda-fc4c-4898-fc3b-c29faec093af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word2Vec :\n",
            "Word2Vec(vocab=752, size=100, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the embedding vector for a specific word\n",
        "print(\"Embedding Vector for Audi : \", w2v_model['Audi'], sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRgFwv9p80HX",
        "outputId": "858f1586-d95f-4cfd-f812-5baaa767436e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Vector for Audi : \n",
            "[ 0.5044263   0.34770858 -0.0638372  -0.3189772  -0.08491277 -0.45134172\n",
            " -0.23854408 -0.33530536  0.3076679  -0.13442138  0.00591657  0.3686675\n",
            " -0.16924813 -0.13772874 -0.35768571 -0.15862294 -0.3893453   0.37283438\n",
            "  0.53814644  0.15523675  0.02774514  0.06630558 -0.15259778 -0.3319281\n",
            "  0.9990962   0.40906322 -0.39458808 -0.32587063  0.86114115 -0.3133111\n",
            " -0.19215992 -0.5381166  -0.06661527 -0.23726499  0.02297745  0.2006813\n",
            " -0.35913298 -0.36772344 -0.14318204 -0.27630192  0.49682653  0.75089025\n",
            "  0.15991527  0.48038432 -0.5071131   0.54681826 -0.14039695  0.04161979\n",
            "  0.32185617  0.3189142   0.0144504  -0.12769185 -0.10586888  0.19949545\n",
            "  0.16830006  0.2852649   0.15174691  0.16381378  0.2603552  -0.64330894\n",
            " -0.22704309 -0.59486026  0.13079247  0.40255865 -0.24674995 -0.40300277\n",
            " -0.05535044 -0.7643973   0.4182064  -0.5971203  -0.02811981  0.51519084\n",
            "  0.5162952   0.46689016 -0.14160074  0.06851733 -0.02190312  0.1501793\n",
            "  0.17352587 -0.436448   -0.0147089  -0.28886935 -0.35862345 -0.16338144\n",
            "  0.31801924 -0.76523656  0.43795562  1.0449299   0.15265083 -0.04059589\n",
            "  0.24330153 -0.80278385  0.63228196  0.0980821  -0.19142099  0.14659762\n",
            " -0.06890593  0.66851676  0.46210685  0.4486162 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-6a5b3a9cbba5>:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  print(\"Embedding Vector for Audi : \", w2v_model['Audi'], sep=\"\\n\")\n"
          ]
        }
      ]
    }
  ]
}